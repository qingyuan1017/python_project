{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "<center>\n",
    "<h1>Lecture 7: Boosting</h1>\n",
    "<br>\n",
    "<h3>Advanced Business Analytics (CIS442D/85)</h3>\n",
    "<h3>Simon Business School</h3>\n",
    "<h3>2/15/2017</h3>\n",
    "</center> \n",
    "\n",
    "Some of the figures in this presentation are taken from \"An Introduction to Statistical Learning, with applications in R\"  (Springer, 2013) with permission from the authors: G. James, D. Witten,  T. Hastie and R. Tibshirani \n",
    "(<a href=\"http://www-bcf.usc.edu/~gareth/ISL/\">link</a>)\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bootstrap aggregation (Bagging)\n",
    "## Bootstrap\n",
    "- Original input data (5 data points)\n",
    "    \n",
    "<img src=\"figures/bootstrap1.png\" style=\"max-width:25%;height:auto;\"/>\n",
    "\n",
    "- $B=3$ bootstrapped data sets (with repetition)\n",
    "    \n",
    "<img src=\"figures/bootstrap2.png\" style=\"max-width:80%;height:auto;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "___\n",
    "\n",
    "## Bagging as a linear summation of models\n",
    "\n",
    "\n",
    "- The classifiers $f_b$ were constructed independently from bootstrapped data\n",
    "\n",
    "<img src=\"figures/figure-bagging1.png\" style=\"max-width:60%;height:auto;\"/>\n",
    "\n",
    "- Bagging and random forests can be written as\n",
    "\n",
    "<center>\n",
    "$\n",
    "f(X_1,...,X_p)=\\sum_{b=1}^B f_b(X_1,...,X_p,\\gamma_b)\n",
    "$\n",
    "</center>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br><br><br><br><br>\n",
    "___\n",
    "\n",
    "# 2. Boosting\n",
    "\n",
    "- Introduced in 1995 by Freund and Schapire\n",
    "- Alternative approach to bagging\n",
    "- Sequentially add classifiers (regressors) to improve prediction\n",
    "\n",
    "<img src=\"figures/figure-boosting1.png\" style=\"max-width:50%;height:auto;\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<center>\n",
    "$\n",
    "f(X_1,...,X_p)=\\sum_{b=1}^B \\beta_b f_b(X_1,...,X_p,\\gamma_b)\n",
    "$\n",
    "</center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Example - prediction of disease progression\n",
    "\n",
    "### Dataset\n",
    "* Scikit datasets: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html\n",
    "* Source: http://www4.stat.ncsu.edu/%7Eboos/var.select/diabetes.html\n",
    "* \"Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.\"\n",
    "* AGE SEX BMI BP S1 S2 S3 S4 S5 S6 Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10) (442,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         x8        x9       x10      Y  \n",
       "0 -0.002592  0.019908 -0.017646  151.0  \n",
       "1 -0.039493 -0.068330 -0.092204   75.0  \n",
       "2 -0.002592  0.002864 -0.025930  141.0  \n",
       "3  0.034309  0.022692 -0.009362  206.0  \n",
       "4 -0.002592 -0.031991 -0.046641  135.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset \n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "Y = diabetes.target\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# store in dataframe\n",
    "df = pd.DataFrame(data=np.concatenate([X,Y.reshape(Y.shape[0],1)],axis=1),columns=['x%d'%i for i in range(1,11)]+['Y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.22259211  0.40957228  0.38868188  0.20381595  0.36922476]\n",
      "Accuracy: 0.32 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "# Prediction using regression tree\n",
    "reg = DecisionTreeRegressor(max_depth=3)\n",
    "scores = cross_val_score(reg, X, Y, cv=5) # R^2 \n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.36477824  0.51257571  0.46013131  0.36623174  0.4723518 ]\n",
      "Accuracy: 0.44 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "# Prediction using random forest\n",
    "reg_rf = RandomForestRegressor(max_depth =3, n_estimators=50)\n",
    "scores = cross_val_score(reg_rf, X, Y, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdaBoostRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8485cef5dcee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Prediction using boosting of decision trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreg_boosting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_boosting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %0.2f (+/- %0.2f)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AdaBoostRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "# Prediction using boosting of decision trees\n",
    "reg_boosting = AdaBoostRegressor(base_estimator=reg, learning_rate =0.1)\n",
    "scores = cross_val_score(reg_boosting, X, Y, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Illustration of boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>Y</th>\n",
       "      <th>Prediction 0</th>\n",
       "      <th>Residuals 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         x8        x9       x10      Y  Prediction 0  Residuals 0  \n",
       "0 -0.002592  0.019908 -0.017646  151.0             0        151.0  \n",
       "1 -0.039493 -0.068330 -0.092204   75.0             0         75.0  \n",
       "2 -0.002592  0.002864 -0.025930  141.0             0        141.0  \n",
       "3  0.034309  0.022692 -0.009362  206.0             0        206.0  \n",
       "4 -0.002592 -0.031991 -0.046641  135.0             0        135.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma=0.5 # learning_rate/shrinkage_parameter\n",
    "\n",
    "# initalize residuals\n",
    "df['Prediction 0'] = 0\n",
    "df['Residuals 0'] = df['Y']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>Y</th>\n",
       "      <th>Prediction 0</th>\n",
       "      <th>Residuals 0</th>\n",
       "      <th>Prediction 1</th>\n",
       "      <th>Residuals 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>104.285714</td>\n",
       "      <td>46.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>41.684524</td>\n",
       "      <td>33.315476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>104.285714</td>\n",
       "      <td>36.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>88.432432</td>\n",
       "      <td>117.567568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>54.402299</td>\n",
       "      <td>80.597701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         x8        x9       x10      Y  Prediction 0  Residuals 0  \\\n",
       "0 -0.002592  0.019908 -0.017646  151.0             0        151.0   \n",
       "1 -0.039493 -0.068330 -0.092204   75.0             0         75.0   \n",
       "2 -0.002592  0.002864 -0.025930  141.0             0        141.0   \n",
       "3  0.034309  0.022692 -0.009362  206.0             0        206.0   \n",
       "4 -0.002592 -0.031991 -0.046641  135.0             0        135.0   \n",
       "\n",
       "   Prediction 1  Residuals 1  \n",
       "0    104.285714    46.714286  \n",
       "1     41.684524    33.315476  \n",
       "2    104.285714    36.714286  \n",
       "3     88.432432   117.567568  \n",
       "4     54.402299    80.597701  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a regression tree\n",
    "reg = DecisionTreeRegressor(max_depth=3)\n",
    "reg.fit(X,df['Residuals 0'])\n",
    "\n",
    "# add prediction to dataframe\n",
    "df['Prediction 1']=df['Prediction 0']+gamma*reg.predict(X)\n",
    "df.head()\n",
    "\n",
    "# compute residuals\n",
    "df['Residuals 1'] = df['Residuals 0']-gamma*reg.predict(X)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27a38446668>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAFkCAYAAABvkjJwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27a3a5f1710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how far is the current prediction from Y\n",
    "df['Residuals 1'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>Y</th>\n",
       "      <th>Prediction 0</th>\n",
       "      <th>Residuals 0</th>\n",
       "      <th>Prediction 1</th>\n",
       "      <th>Residuals 1</th>\n",
       "      <th>Prediction 2</th>\n",
       "      <th>Residuals 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>104.285714</td>\n",
       "      <td>46.714286</td>\n",
       "      <td>160.402891</td>\n",
       "      <td>-9.402891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>41.684524</td>\n",
       "      <td>33.315476</td>\n",
       "      <td>66.537128</td>\n",
       "      <td>8.462872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>104.285714</td>\n",
       "      <td>36.714286</td>\n",
       "      <td>134.677872</td>\n",
       "      <td>6.322128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>88.432432</td>\n",
       "      <td>117.567568</td>\n",
       "      <td>132.029279</td>\n",
       "      <td>73.970721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>54.402299</td>\n",
       "      <td>80.597701</td>\n",
       "      <td>79.254903</td>\n",
       "      <td>55.745097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         x8        x9       x10      Y  Prediction 0  Residuals 0  \\\n",
       "0 -0.002592  0.019908 -0.017646  151.0             0        151.0   \n",
       "1 -0.039493 -0.068330 -0.092204   75.0             0         75.0   \n",
       "2 -0.002592  0.002864 -0.025930  141.0             0        141.0   \n",
       "3  0.034309  0.022692 -0.009362  206.0             0        206.0   \n",
       "4 -0.002592 -0.031991 -0.046641  135.0             0        135.0   \n",
       "\n",
       "   Prediction 1  Residuals 1  Prediction 2  Residuals 2  \n",
       "0    104.285714    46.714286    160.402891    -9.402891  \n",
       "1     41.684524    33.315476     66.537128     8.462872  \n",
       "2    104.285714    36.714286    134.677872     6.322128  \n",
       "3     88.432432   117.567568    132.029279    73.970721  \n",
       "4     54.402299    80.597701     79.254903    55.745097  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit a regression tree\n",
    "reg = DecisionTreeRegressor(max_depth=3)\n",
    "reg.fit(X,df['Residuals 1'])\n",
    "\n",
    "# add prediction to dataframe\n",
    "df['Prediction 2']=df['Prediction 1']+gamma*reg.predict(X)\n",
    "df.head()\n",
    "\n",
    "# compute residuals\n",
    "df['Residuals 2'] = df['Residuals 1']-gamma*reg.predict(X)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27a3a5b9be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAFkCAYAAABvkjJwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27a3a5f1cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how far is the current prediction from Y\n",
    "df['Residuals 2'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Boosting for regression trees *\n",
    "From \"An introduction to statistical learning\" (Chapter 8)\n",
    "\n",
    "1. Set $f(x)=0$ and $r_i=y_i$ in the training data set\n",
    "2. for $b=1,2,...,B$ repeat:\n",
    "    1. Fit a tree $f^b$ to the training data $(X,r)$\n",
    "    2. Update $f$ by adding in a shrunken version of the new tree\n",
    "<center>\n",
    "$f(x) \\leftarrow f(x) + \\lambda f^b(x)$\n",
    "</center>\n",
    "\n",
    "    3. Update the residuals\n",
    "<center>\n",
    "$r_i \\leftarrow r_i - \\lambda f^b(x_i)$\n",
    "</center>\n",
    "\n",
    "3. Output the boosted model,\n",
    "<center>\n",
    "$f(x)=\\sum_{b=1}^{B}\\lambda f^b(x)$\n",
    "</center>\n",
    "\n",
    "\n",
    "$\\lambda$ - shrinkage parameter (slows the learning process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "___\n",
    "\n",
    "## 2.4 Forward stage-wise additive modeling *\n",
    "\n",
    "\n",
    "* How to learn the parameters $\\beta_b$ and $\\gamma_b$?\n",
    "\n",
    "<center>\n",
    "$f(X_1,...,X_p)=\\sum_{b=1}^B \\beta_b f_b(X_1,...,X_p,\\gamma_b)$\n",
    "</center>\n",
    "\n",
    "* Hard optimization problem \n",
    "\n",
    "* Heuristic (forward stage-wise additive modeling)\n",
    "    1. Initialize $f_0 = 0$\n",
    "    2. For $b=1...B$:\n",
    "        \n",
    "        a. Compute \n",
    "        <center>\n",
    "        $\n",
    "        \\beta_b,\\gamma_b = arg \\min_{\\beta,\\gamma} \\sum_{i=1}^{N}L(y_i,f_{b-1}(\\bar{x}_i)+\\beta f(\\bar{x}_i,\\gamma))\n",
    "        $\n",
    "        </center>\n",
    "\n",
    "        b. Set $f_b=f_{b-1} + \\beta_b f(x,\\gamma_b)$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br><br><br><br><br>\n",
    "___\n",
    "\n",
    "## (2.5) Summary\n",
    "\n",
    "* Boosting for regression problems\n",
    "\n",
    "* Boosting for classification problems\n",
    "    * Boosting works well even with very simple classifiers (weak learners)\n",
    "    * Decision stump - tree with a single split\n",
    "    * Error rate close to 0.5\n",
    "    * Why error rate always below 0.5?\n",
    "\n",
    "* Bagging/Boosting are meta-algorithms (not only on trees)\n",
    "\n",
    "- References\n",
    "    - An Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani\n",
    "    - Pattern Recognition and Machine Learning by Christopher Bishop \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
